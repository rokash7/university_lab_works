{"cells":[{"cell_type":"markdown","metadata":{"id":"WZxRYf-FRWOt"},"source":["Rokas Petrauskas 1gr. 2pogr."]},{"cell_type":"markdown","metadata":{"id":"RvjvlkdjUP8_"},"source":["Importai"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uHPkAJEG-Xt5"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms, datasets\n","from PIL import Image\n","from torchvision.transforms import ToTensor, Normalize, Compose\n","import os\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"I5ici97Cr1wm"},"source":["gdrive mount"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19084,"status":"ok","timestamp":1683709378997,"user":{"displayName":"Rokas Petrauskas","userId":"11558678322288088780"},"user_tz":-180},"id":"1qmtpTv8BVco","outputId":"5983731f-07be-41b1-df6b-3ea47d01461e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["# google drive\n","\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xt1ZQ322BtJ4"},"outputs":[],"source":["google_drive_dir = \"/content/gdrive/MyDrive/gmm_lab3/data\""]},{"cell_type":"markdown","metadata":{"id":"MISmSpk0r9sA"},"source":["Pic download, creating directories and moving pictures to required directories.\n","\n","Commented so it is not run when running all code since all the data is stored in google drive."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1XIUG5mvBUW5"},"outputs":[],"source":["# import os\n","# import fiftyone as fo\n","# import fiftyone.zoo as foz\n","# import random\n","# import shutil\n","\n","\n","# # vienos klases nuotrauku ir ju kaukiu atsiuntimas & export\n","# def exportClassDataset(className, num_samples = 10):\n","#   dataset_class = foz.load_zoo_dataset(\n","#     \"open-images-v6\",\n","#     \"train\",\n","#     label_types=[\"segmentations\"],\n","#     classes=[className],\n","#     max_samples=num_samples,\n","#     seed=51,\n","#     shuffle=False,\n","#     dataset_name=\"open-images-\"+className,\n","#     overwrite=True\n","#   )\n","\n","#   set_dir = os.path.join(google_drive_dir, className, \"all\")\n","#   os.makedirs(set_dir, exist_ok=True)\n","\n","#   dataset_class.export(\n","#       export_dir=set_dir,\n","#       dataset_type=fo.types.ImageSegmentationDirectory\n","#   )\n","\n","#   fo.delete_dataset(\"open-images-\"+className)\n","\n","#   return set_dir\n","\n","# # padalinimas i train/validation/test directories su 0.7/0.2/0.1 santykiu\n","# def splitExported(set_dir, className):\n","#   train_dir = os.path.join(google_drive_dir, className, \"train\")\n","#   validation_dir = os.path.join(google_drive_dir, className, \"validation\")\n","#   test_dir = os.path.join(google_drive_dir, className, \"test\")\n","\n","#   os.makedirs(train_dir, exist_ok=True)\n","#   os.makedirs(validation_dir, exist_ok=True)\n","#   os.makedirs(test_dir, exist_ok=True)\n","\n","#   # Set the split ratios\n","#   train_split = 0.7\n","#   validation_split = 0.2\n","#   test_split = 0.1\n","\n","#   # Get all image filenames\n","#   all_images_dir = os.path.join(set_dir, \"data\")\n","#   all_masks_dir = os.path.join(set_dir, \"labels\")\n","\n","#   all_images = os.listdir(all_images_dir)\n","\n","#   # Shuffle the filenames\n","#   random.seed(42)\n","#   random.shuffle(all_images)\n","\n","#   # Calculate the number of samples for each split\n","#   num_train = int(len(all_images) * train_split)\n","#   num_validation = int(len(all_images) * validation_split)\n","\n","#   # Split the data\n","#   train_images = all_images[:num_train]\n","#   validation_images = all_images[num_train:num_train + num_validation]\n","#   test_images = all_images[num_train + num_validation:]\n","\n","#   # Move the files to the respective directories\n","#   def move_files(src_images_dir, src_masks_dir, dst_images_dir, dst_masks_dir, filenames):\n","#       for filename in filenames:\n","#           src_image_path = os.path.join(src_images_dir, filename)\n","#           dst_image_path = os.path.join(dst_images_dir, filename)\n","#           shutil.move(src_image_path, dst_image_path)\n","\n","#           mask_filename = os.path.splitext(filename)[0] + \".png\"\n","#           src_mask_path = os.path.join(src_masks_dir, mask_filename)\n","#           dst_mask_path = os.path.join(dst_masks_dir, mask_filename)\n","#           shutil.move(src_mask_path, dst_mask_path)\n","\n","#   os.makedirs(os.path.join(train_dir, \"data\"), exist_ok=True)\n","#   os.makedirs(os.path.join(train_dir, \"labels\"), exist_ok=True)\n","#   move_files(all_images_dir, all_masks_dir, os.path.join(train_dir, \"data\"), os.path.join(train_dir, \"labels\"), train_images)\n","\n","#   os.makedirs(os.path.join(validation_dir, \"data\"), exist_ok=True)\n","#   os.makedirs(os.path.join(validation_dir, \"labels\"), exist_ok=True)\n","#   move_files(all_images_dir, all_masks_dir, os.path.join(validation_dir, \"data\"), os.path.join(validation_dir, \"labels\"), validation_images)\n","\n","#   os.makedirs(os.path.join(test_dir, \"data\"), exist_ok=True)\n","#   os.makedirs(os.path.join(test_dir, \"labels\"), exist_ok=True)\n","#   move_files(all_images_dir, all_masks_dir, os.path.join(test_dir, \"data\"), os.path.join(test_dir, \"labels\"), test_images)\n","\n","#   # Clean up empty \"all\" directories\n","#   shutil.rmtree(all_images_dir)\n","#   shutil.rmtree(all_masks_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I6ICS_lVC8Fo"},"outputs":[],"source":["# # nuotrauku atsisiuntimas, eksportavimas ir paskirstymas\n","\n","# classes = [\"Banana\", \"Bear\", \"Sock\"]\n","\n","# for class_i in classes:\n","#   print(class_i)\n","#   dir = exportClassDataset(class_i, 100)\n","#   splitExported(dir, class_i)\n"]},{"cell_type":"markdown","metadata":{"id":"FUdOniifsVnF"},"source":["Moving all to GPU"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1683709388054,"user":{"displayName":"Rokas Petrauskas","userId":"11558678322288088780"},"user_tz":-180},"id":"FNnuIcfhHYOT","outputId":"2b2ac37d-0603-4d9d-ced8-f026477ec11f"},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]}],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"lwpL0JganfMG"},"source":["data loader\n","\n","custom dataset is needed to load picture with the corresponding mask."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DoAsWzRpngW3"},"outputs":[],"source":["data_dirs = [\n","        \"/content/gdrive/MyDrive/gmm_lab3/data/Banana\",\n","        \"/content/gdrive/MyDrive/gmm_lab3/data/Bear\",\n","        \"/content/gdrive/MyDrive/gmm_lab3/data/Sock\",\n","    ]\n","\n","n_classes = 4\n","input_size = (256, 256)\n","batch_size = 16\n","n_epochs = 2\n","\n","# class CustomDataset(Dataset):\n","#     def __init__(self, data_dirs, mode, transform=None):\n","#         self.data_dirs = data_dirs\n","#         self.mode = mode\n","#         self.transform = transform\n","#         self.image_label_list = []\n","        \n","#         for class_num, data_dir in enumerate(data_dirs, 2):\n","#             image_list = sorted(os.listdir(os.path.join(data_dir, mode, \"data\")))\n","#             label_list = sorted(os.listdir(os.path.join(data_dir, mode, \"labels\")))\n","            \n","#             for image_file, label_file in zip(image_list, label_list):\n","#                 image_path = os.path.join(data_dir, mode, \"data\", image_file)\n","#                 label_path = os.path.join(data_dir, mode, \"labels\", label_file)\n","#                 self.image_label_list.append((image_path, label_path, class_num))\n","\n","#     def __len__(self):\n","#         return len(self.image_label_list)\n","\n","#     def __getitem__(self, idx):\n","#         image_path, label_path, class_num = self.image_label_list[idx]\n","#         image = Image.open(image_path).convert(\"RGB\")\n","#         label = Image.open(label_path).convert(\"L\")\n","#         label = (np.array(label) > 0).astype(np.int32) * (class_num - 1)\n","        \n","#         if self.transform:\n","#             image = self.transform(image)\n","#             label = transforms.Resize((224, 224))(label)\n","\n","#         # label = torch.from_numpy(label)\n","            \n","#         return image, label\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, data_dirs, mode, transform=None):\n","        self.data_dirs = data_dirs\n","        self.mode = mode\n","        self.transform = transform\n","        self.image_label_list = []\n","        \n","        for class_num, data_dir in enumerate(data_dirs, 2):\n","            image_list = sorted(os.listdir(os.path.join(data_dir, mode, \"data\")))\n","            label_list = sorted(os.listdir(os.path.join(data_dir, mode, \"labels\")))\n","            \n","            for image_file, label_file in zip(image_list, label_list):\n","                image_path = os.path.join(data_dir, mode, \"data\", image_file)\n","                label_path = os.path.join(data_dir, mode, \"labels\", label_file)\n","                self.image_label_list.append((image_path, label_path, class_num))\n","\n","    def __len__(self):\n","        return len(self.image_label_list)\n","\n","    def __getitem__(self, idx):\n","        image_path, label_path, class_num = self.image_label_list[idx]\n","        image = Image.open(image_path).convert(\"RGB\")\n","        label = Image.open(label_path).convert(\"L\")\n","        label = (np.array(label) > 0).astype(np.int32) * (class_num + 1)\n","        \n","        if self.transform:\n","            image = self.transform(image)\n","            label = np.array(label)\n","            label = Image.fromarray(label)\n","            label = transforms.Resize((224, 224))(label)\n","            label = np.array(label)\n","\n","        label = torch.from_numpy(label)\n","            \n","        return image, label\n","\n","transform_train = transforms.Compose([\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.ColorJitter(brightness=0.3, contrast=0.2, saturation=0.2, hue=0.1),\n","    transforms.RandomRotation(20),\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","])\n","\n","# def custom_collate(batch):\n","#     images = []\n","#     labels = []\n","\n","#     for item in batch:\n","#         images.append(item[0])\n","#         labels.append(item[1])\n","\n","#     images = torch.stack(images, dim=0)\n","#     labels = torch.stack(labels, dim=0)\n","\n","#     return images, labels\n","\n","train_dataset = CustomDataset(data_dirs, \"train\", transform = transform_train)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n","\n","\n","test_dataset = CustomDataset(data_dirs, \"test\", transform = transform_test)\n","test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)\n"]},{"cell_type":"markdown","metadata":{"id":"vrvvU2BGUN5r"},"source":["---\n","\n","**KLASES**: BANANA, BEAR, SOCK\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"1QjRJgeymeV1"},"source":["modelio architektura"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xUjfQV6smYLO"},"outputs":[],"source":["class SegmentationModel(nn.Module):\n","    def __init__(self, n_classes=4):\n","        super(SegmentationModel, self).__init__()\n","        self.n_classes = n_classes\n","        # Define convolutional layers\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(128)\n","        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n","        self.bn3 = nn.BatchNorm2d(256)\n","        # Define final segmentation layer\n","        self.segmentation_layer = nn.Conv2d(256, n_classes, kernel_size=1)\n","\n","    def forward(self, x):\n","        # Pass input through convolutional layers\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = F.relu(self.bn3(self.conv3(x)))\n","        # Pass through segmentation layer and apply softmax\n","        x = self.segmentation_layer(x)\n","        x = F.softmax(x, dim=1)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"9rnPX5jBnI91"},"source":["loss function and optimizer used a few cells lower. changed to fix bugs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mx8ZMAECm5Fm"},"outputs":[],"source":["# model = SegmentationModel(n_classes=4)\n","# loss_fn = nn.CrossEntropyLoss()\n","# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"markdown","metadata":{"id":"OFlij4A2mgWG"},"source":["train loop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_4nk91EaiYMo"},"outputs":[],"source":["# def train(model, train_loader, test_loader, optimizer, criterion, n_epochs):\n","#     for epoch in range(n_epochs):\n","#         # Train\n","#         model.train()\n","#         train_loss = 0.0\n","#         for batch_idx, (data, target) in enumerate(train_loader):\n","#             optimizer.zero_grad()\n","#             output = model(data)\n","#             loss = criterion(output, target)\n","#             loss.backward()\n","#             optimizer.step()\n","#             train_loss += loss.item()\n","#         train_loss /= len(train_loader)\n","        \n","#         # Evaluate on test set\n","#         model.eval()\n","#         test_loss = 0.0\n","#         correct = 0\n","#         total = 0\n","#         with torch.no_grad():\n","#             for batch_idx, (data, target) in enumerate(test_loader):\n","#                 output = model(data)\n","#                 loss = criterion(output, target)\n","#                 test_loss += loss.item()\n","                \n","#         test_loss /= len(test_loader)\n","        \n","#         # Print progress\n","#         print('Epoch: {}, Train Loss: {:.4f}, Test Loss: {:.4f}'.format(epoch+1, train_loss, test_loss))\n","\n","def train(model, train_loader, test_loader, optimizer, criterion, n_epochs):\n","    for epoch in range(n_epochs):\n","        running_loss = 0.0\n","        for i, data in enumerate(train_loader, 0):\n","            inputs, labels = data\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels.long())  # convert labels to long data type since it throws an error with int32\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","            \n","        print(f\"Epoch {epoch+1}, loss: {running_loss/len(train_loader)}\")"]},{"cell_type":"markdown","metadata":{"id":"6fz_IXWetNCH"},"source":["This defines the model, optimizer and loss function\n","\n","the training loop is started here"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pzE8uHCgifKu"},"outputs":[],"source":["model = SegmentationModel()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","criterion = F.nll_loss\n","n_epochs = 10\n","\n","# train(model, train_loader, test_loader, optimizer, criterion, n_epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":619,"status":"ok","timestamp":1683711216804,"user":{"displayName":"Rokas Petrauskas","userId":"11558678322288088780"},"user_tz":-180},"id":"bkcVWfr2v-0j","outputId":"e564dd8b-054d-4594-f7d7-e5a56a90940d"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["PATH = '/content/gdrive/MyDrive/gmm_lab3/model.pth'\n","\n","# # save\n","# torch.save(model.state_dict(), PATH)\n","\n","# # reload\n","model = SegmentationModel()\n","model.load_state_dict(torch.load(PATH))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DFYZnffSmcZV"},"outputs":[],"source":["# print_freq = len(train_loader)\n","\n","# for epoch in range(n_epochs):\n","#     # Set the model to train mode\n","#     model.train()\n","\n","#     # Iterate over the batches in the train loader\n","#     for batch_idx, (images, labels) in enumerate(train_loader):\n","#         # Zero out the gradients\n","#         optimizer.zero_grad()\n","\n","#         # Feed the batch through the model and obtain the model's predictions\n","#         logits = model(images)\n","\n","#         # Calculate the loss between the predictions and the ground truth labels\n","#         loss = loss_fn(logits, labels)\n","\n","#         # Backpropagate the loss to calculate gradients\n","#         loss.backward()\n","\n","#         # Update the model's parameters using the gradients\n","#         optimizer.step()\n","\n","#         # Print the loss and accuracy at regular intervals\n","#         if batch_idx % print_freq == 0:\n","#             print(f\"Epoch [{epoch}/{n_epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n","\n","# # # save\n","# PATH = '/content/gdrive/MyDrive/gmm_lab3/LOCAL01.pth'\n","# torch.save(model.state_dict(), PATH)\n","# # # reload\n","# # net = Net()\n","# # net.load_state_dict(torch.load(PATH))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":34633,"status":"ok","timestamp":1683713885231,"user":{"displayName":"Rokas Petrauskas","userId":"11558678322288088780"},"user_tz":-180},"id":"YK5Azggzqk5E","outputId":"892bf71a-a5c9-4674-d8ca-967e5a6a1ec9"},"outputs":[],"source":["from sklearn.metrics import f1_score\n","from sklearn.metrics import confusion_matrix\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import precision_recall_fscore_support\n","\n","model.eval()\n","\n","def dice_coefficient(prediction, target, smooth=1.):\n","    prediction = torch.from_numpy(prediction).reshape(-1)\n","    target = target.reshape(-1)\n","    intersection = (prediction * target).sum()\n","    dice = (2. * intersection + smooth) / (prediction.sum() + target.sum() + smooth)\n","    return dice.item()\n","\n","with torch.no_grad():\n","    dice_scores = []\n","    micro_f1_scores = []\n","    macro_f1_scores = []\n","    test_loss = 0\n","    true_labels_list = []\n","    pred_labels_list = []\n","    \n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        loss = criterion(outputs, labels.to(torch.long).to(device))\n","        test_loss += loss.item() * images.size(0)\n","\n","        predicted_labels = torch.argmax(outputs, dim=1)\n","        predicted_labels = predicted_labels.cpu().numpy()\n","        true_labels = labels.cpu().numpy()\n","\n","        for i in range(len(true_labels)):\n","            dice_score = dice_coefficient(predicted_labels[i], true_labels[i])\n","            dice_scores.append(dice_score)\n","            \n","            true_labels_list.extend(list(true_labels[i].flatten()))\n","            pred_labels_list.extend(list(predicted_labels[i].flatten()))\n","\n","        # Display a few images and predicted labels\n","        for i in range(3):\n","            plt.figure(figsize=(10, 5))\n","            plt.subplot(1, 2, 1)\n","            plt.imshow(np.transpose(images[i], (1, 2, 0)))\n","            plt.title(\"Image\")\n","            plt.axis(\"off\")\n","\n","            plt.subplot(1, 2, 2)\n","            plt.imshow(predicted_labels[i])\n","            plt.title(\"Predicted label\")\n","            plt.axis(\"off\")\n","\n","            plt.show()\n","\n","    average_dice = np.mean(dice_scores)\n","    test_loss /= len(test_loader.dataset)\n","\n","    # Calculate micro- and macro-averaged F1 scores\n","    micro_f1 = f1_score(true_labels_list, pred_labels_list, average='micro')\n","    macro_f1 = f1_score(true_labels_list, pred_labels_list, average='macro')\n","\n","    print(f\"Test Dice coefficient: {average_dice:.4f}\")\n","    print(f\"Test loss: {test_loss:.4f}\")\n","    print(f\"Test Micro-F1: {micro_f1:.4f}\")\n","    print(f\"Test Macro-F1: {macro_f1:.4f}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOA1ARt7fuFj2TO1XcOsR5r","gpuType":"T4","mount_file_id":"1X8ECvzqbdQPOdhvEqKr83mVOQqF6cTB5","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":0}
